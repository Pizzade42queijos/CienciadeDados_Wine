# -*- coding: utf-8 -*-
"""Projeto da 2¬™ Unidade

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WkaE5r4EAHcnZY1tNbk1LGImP8mNpwkM

---
# PROJETO DATASET WINE üç∑

Dataset:. https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data


---

IFPE -  Campus Paulista

Curso Tecnol√≥gico em An√°lise e Desenvolvimento de Sistemas

Disciplina: Minera√ß√£o de Dados

Relat√≥rio do Projeto da 2¬™ Unidade

Equipe:

*   Audem√°rio Alves monteiro filho
*   Gaston Gouveia
*   Paola do Nascimento Rodrigues
*   Wagner Vidal Xavier da Silva

# **1. Compreens√£o do Neg√≥cio**

##  **a. Objetivo de Neg√≥cio**

**1. Identifica√ß√£o de Perfis de Vinho:** Analisar os dados para identificar padr√µes exclusivos de composi√ß√£o qu√≠mica que caracterizam os vinhos produzidos por cada produtor.  

**2. Otimiza√ß√£o da Produ√ß√£o:** Identificar fatores espec√≠ficos na composi√ß√£o qu√≠mica que est√£o correlacionados com a qualidade do vinho. Isso pode ajudar os produtores a otimizar seus processos de produ√ß√£o para melhorar a consist√™ncia e qualidade do produto final.

**3. Classifica√ß√£o de Produtores:** Desenvolver modelos preditivos para classificar automaticamente os vinhos de acordo com o produtor com base em suas caracter√≠sticas qu√≠micas. Isso pode ser √∫til para autentica√ß√£o e certifica√ß√£o.

Obs: Decidimos, neste momento, realizar o **item 3,** que trata da **Classifica√ß√£o de Produtores/Classes**, devido ao tempo dispon√≠vel para a conclus√£o do projeto.

## **b. Objetivo de Minera√ß√£o: Que tarefa de minera√ß√£o ser√° realizada para atingir o objetivo de Neg√≥cio?**

Para atingir o objetivo de neg√≥cio de "Classifica√ß√£o de Produtores" com base nas caracter√≠sticas qu√≠micas dos vinhos, uma tarefa de minera√ß√£o comumente realizada √© a Classifica√ß√£o. A **Classifica√ß√£o** √© uma t√©cnica de aprendizado de m√°quina supervisionado, na qual um modelo √© treinado para categorizar inst√¢ncias em classes ou categorias predefinidas.

Aqui est√£o os passos geralmente seguidos para realizar a tarefa de Classifica√ß√£o neste contexto:

1. **Prepara√ß√£o dos Dados:** Organize os dados de forma que cada inst√¢ncia represente um vinho e suas caracter√≠sticas qu√≠micas.
Atribua r√≥tulos (classes) aos vinhos com base nos produtores.


2. **Divis√£o dos Dados:** Separe os dados em conjuntos de treinamento e teste. O conjunto de treinamento √© usado para treinar o modelo, enquanto o conjunto de teste √© usado para avaliar a precis√£o do modelo.

3. **Sele√ß√£o de Caracter√≠sticas:** Identifique as caracter√≠sticas relevantes para a classifica√ß√£o dos produtores. Isso pode envolver uma an√°lise explorat√≥ria para entender a import√¢ncia de cada caracter√≠stica.

4. **Escolha do Modelo de Classifica√ß√£o:** Selecione um modelo de classifica√ß√£o adequado.

5. **Treinamento do Modelo:**Utilize o conjunto de treinamento para treinar o modelo, ajustando os par√¢metros para otimizar o desempenho.

6. **Avalia√ß√£o do Modelo**: Avalie o modelo usando o conjunto de teste para medir a precis√£o da classifica√ß√£o. M√©tricas como acur√°cia, precis√£o, recall e F1-score podem ser utilizadas dependendo das caracter√≠sticas espec√≠ficas do problema.

7. **Interpreta√ß√£o dos Resultados:** Analise os resultados para entender como o modelo est√° classificando os vinhos em rela√ß√£o aos produtores. Isso pode incluir a an√°lise de matrizes de confus√£o para identificar os erros mais comuns.

## **c. Crit√©rios de Sucesso Minera√ß√£o:**

Definimos como crit√©rio prim√°rio de sucesso a obten√ß√£o de uma devida classifica√ß√£o entre os produtores de vinhos presentes do dataset, nosso objetivo de neg√≥cio, que resulte em  boa acur√°cia e n√≠veis aceit√°veis de erros.  

A acur√°cia do modelo ser√° a m√©trica essencial para determinar se este atribui corretamente as classes pr√©-determinadas aos vinhos e consequentemente se √© de boa qualidade.  

Idealmente optar√≠amos por um benchmarking externo, analisando modelos que utilizam a mesma base de dados e compartilham das mesmas inten√ß√µes quanto ao crit√©rio de sucesso para tra√ßar pontos de refer√™ncia, por√©m dada a aparente aus√™ncia de exemplos com o mesmo crit√©rio de sucesso, a classifica√ß√£o entre os produtores, optaremos por um benckmarking interno, comparando os resultados individuais do crit√©rio de sucesso entre os cinco algoritmos utilizados.

# **2.Compreens√£o dos dados**

1. **Introdu√ß√£o aos Dados:**

A base de dados utilizada √© uma base de dados com 178 inst√¢ncias diferentes de vinhos, divididas em tr√™s grandes classes e mais 13 atributos que representam caracter√≠sticas qu√≠micas dos exemplares e incluem diversas medidas como teor alco√≥lico, √°cido m√°lico, cinzas, alcalinidade das cinzas, magn√©sio, fen√≥is totais, flavonoides, fen√≥is n√£o flavonoides, proantocianidinas, intensidade de cor, matiz e OD280/OD315 de vinhos dilu√≠dos.

### Instala√ß√£o e Importa√ß√£o das ferramentas necess√°rias
"""

#INSTALANDO OPTIMIZADORES
!pip install tpot
!pip install eli5

#Instala√ß√£o do Pandas Profiling
!pip install --upgrade scipy

!pip install typing_extensions==4.7.1 --upgrade

!pip install ydata-profiling

# Importando bibliotecas que ser√£o utilizadas para an√°lise e modelagem
from ydata_profiling import ProfileReport

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
pd.options.display.float_format = '{:.3f}'.format
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_curve
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.svm import SVC, LinearSVC
from sklearn.feature_selection import SelectPercentile
from sklearn.metrics import precision_score, recall_score




# %matplotlib inline

# Carregamento do conjunto de dados no Pandas
df = pd.read_csv('Base de dados - Wine.csv')
df.head(5)

"""## **Dicion√°rio dos dados**

1.   Alcohol: √Ålcool
2.   Malic acid: √Åcido m√°lico
3.   Ash: Cinzas
4.   Alcalinity of ash: Alcalinidade das cinzas
5.   Magnesium: Magn√©sio
6.   Total phenols: Fen√≥is totais
7.   Flavanoids: Flavonoides
8.   Nonflavanoid phenols: Fen√≥is n√£o flavonoides
9.   Proanthocyanins: Proantocianinas
10.  Color intensity: Intensidade da cor
11.  Hue: Matiz
12.  OD280/OD315 of diluted wines: OD280/OD315 de vinhos dilu√≠dos
13.  Proline: Prolina

## Tipos de Dados
"""

# Aqui verificamos quais as features obeservadas, os tipos delas(num√©ricas ou categ√≥rica) e se precisam de algum pr√©-processamento:
# Conforme observado, o dataset n√£o precisar√° de estrat√©gi para os dados ausentes, j√° que est√° todo preenchido e tamb√©m podemos observar os tipos das vari√°veis
df.info()

# Renomear colunas
df = df.rename(columns = {'Alcohol' : 'Alcool',	'Malicacid': 'Acido_Malico'	,'Ash': 'Cinzas','Alcalinity_of_ash': 'Alcalinidade_de_cinzas'
,'Magnesium': 'Magnesio'	,'Total_phenols': 'Total_fenois','Flavanoids': 'Flavonoides'	,'Nonflavanoid_phenols':'Fenois_n√£o-flavanoides'
,'Proanthocyanins':'Proantocianinas','Color_intensity':'Cor_intensidade','Hue':'Tonalidade'
,'0D280_0D315_of_diluted_wines':'OD280 / OD315 de vinhos dilu√≠dos'	,'Proline':'Prolina','class':'classe'})
df.columns

print('A base de dados tem ', df.shape[0] , 'linhas e ', df.shape[1], 'colunas.')

"""Possu√≠mos no total quatorze vari√°veis. Tr√™s delas, "n√≠veis de magn√©sio, proline e classe", s√£o representadas de forma qualitativa utilizando distin√ß√£o por classes num√©ricas de tipo int64, e outra, "intensidade de cor", representada em um tipo object.  

As demais dez vari√°veis s√£o de tipo num√©rico float64. N√£o possu√≠mos dados faltantes de tipo _null_ ou _NaN_.
"""

df.shape

# Alguns par√¢metros estat√≠sticos da base
# Estat√≠stica descritiva de todas as colunas do DataFrame
df.describe(include = 'all')

"""A partir da descri√ß√£o dos dados tomamos nota de algumas caracter√≠sticas iniciais relacionadas aos seus tipos, tal como se encontram.  

A vari√°vel intensidade de cores de tipo object possui 132 valores √∫nicos, com os 46 valores possu√≠ndo no m√≠nimo uma repeti√ß√£o onde o valor mais repetido, 2.6, possui 4 repeti√ß√µes. Das vari√°veis de tipo float64 ou int64 podemos extrair informa√ß√µes estatisticas como m√©dia, moda e desvio padr√£o. Percebemos desde j√° que a vari√°vel tonalidade possui alto desvio padr√£o, por exemplo.  

Ademais, como √© esperado, todos os valores possuem a mesma quantidade de linhas, tornando poss√≠vel a utiliza√ß√£o dos dados como dataset.

## An√°lise explorat√≥ria de Dados:

Utiliza√ß√£o do Pandas Profiling:
"""

profile = ProfileReport(df)
profile

eda_data = df.copy()

"""**Compreendendo as colunas de dados:**

1. **Alcool:**   
Alcool apresenta uma distribui√ß√£o normal com concentra√ß√£o dos valores pr√≥ximos a m√©dia  
Possui alta correla√ß√£o com Prolina e Classe, onde valores menores de Alcool tendem a classe 1 e valores menores tendem a classe 3.  
Distribui-se de forma quase uniforme entre as classes, sendo a classe 1 majorit√°ria.   
...  
  
2. **√Åcido M√°lico:**   
Acido M√°lico apresenta uma distribui√ß√£o unimodal enviesada a esquerda.  
Possui alta correla√ß√£o com Tonalidade
...  
  
3. **Cinzas:**  
Cinzas apresenta uma distribui√ß√£o normal e unimodal
...  
  
4. **Alcanilidade de cinzas:**  
Alcalinidade de cinzas apresenta uma distribui√ß√£o normal e unimodal.
...   
  
5. **Magn√©sio:**  
Marn√©sio apresenta uma disbribui√ß√£o unimodal enviesada a esquerda.  
Possui alta correla√ß√£o com Prolina.
...  
   
6. **Total de Fenois:**  
Total de Fenois apresenta uma distribui√ß√£o unimodal.  
Possui alta correla√ß√£o com Flavonoides, Proantocianinas, OD280/OD315 e Classe
...  
   
7. **Flavanoides:**  
Flavonoides apresenta uma distribui√ß√£o bimodal enviesada a esquerda.
Possui alta correla√ß√£o negativa com Fenois n√£o Flavanoides e correla√ß√£o positiva com OD280/OD315, Total de Fenois, Tonalidade e Classe
...  
  
8. **Fenois n√£o Flavanoides:**  
Fenois n√£o flavanoides apresenta uma distribui√ß√£o unimodal levemente enviesada a esquerda.  
Possui alta correla√ß√£o negativa com Flavanoides, OD280/OD315, Total de Fenois e Classe.
...  
  
9. **Proantocianinas:**  
Proantocianinas apresenta uma distribui√ß√£o unimodal enviesada a esquerda.  
Possui alta correla√ß√£o com Flavonoides, OD280/OD315 e Total de Fenois.
...  
  
10. **Cor Intensidade:**   
Cor Intensidade apresenta uma distribui√ß√£o bimodal.
...  
  
11. **Tonalidade:**  
Tonalidade apresenta uma distribui√ß√£o bimodal levemente enviesada a direita.  
Possui uma alta correla√ß√£o com √°cido malico e flavanoides.
...
  
12. **OD280/OD315:**  
OD280/OD315 apresenta uma distribui√ß√£o bimodal levemente enviesada a direita.  
Possui alta correla√ß√£o com flavanoides, proantocianinas, total de fenois e classe.
...
  
13. **Prolina:**  
Prolina apresenta uma distribui√ß√£o unimodal enviesada a esquerda.  
Possui alta correla√ß√£o com √°lcool, magn√©sio e classe.
...
  
14. **Classe:**  
A distribui√ß√£o de classes segue uma distribui√ß√£o normal, com a classe 2 sendo predominante.

Podemos concluir dessa an√°lise que existe uma forte rela√ß√£o entre a quantidade de fen√≥is em um vinho e sua classifica√ß√£o.. //continuar//
"""

#Gerando os histogramas
plt.figure(figsize= (25,15))
for i, column in enumerate(eda_data.columns):
  plt.subplot(4, 6, i +1)
  sns.histplot(data=eda_data[column])
  plt.title(column)
plt.tight_layout()
plt.show()

"""Correla√ß√£o de dados"""

# Exibir correla√ß√µes
df.corr()

# Mapa de calor - exibi√ß√£o das correla√ß√µes
corr = df.corr()
fig, ax = plt.subplots(figsize=(12, 12))
sns.heatmap(corr, annot=True, cmap="BuPu")

grouped=df.groupby(by='classe').mean()
grouped

"""Abaixo esbo√ßamos gr√°ficos e com eles observamos a distribui√ß√£o de vari√°veis em rela√ß√£o as classes quanto a seus valores:
Verificamos qual classe contem os valores mais altos e/ou baixos de cada vari√°vel, podendo cruzar essa rela√ß√£o com a diferen√ßa/correla√ß√£o entre vari√°veis, v√°riancia e desvio padr√£o de cada vari√°vel. Dito isso, algumas observa√ß√µes que chamam aten√ß√£o, a exemplo de:

1. Os valores acima de 2.0~ de √°cido m√°lico pertendem a _classe 3_  
2. Em flavonoides os valores pertencentes a _classe 3_ n√£o passam de 1.0
3. Em tonalidade h√° um grande desbalanceamento nas classes, com tons acima de 1~ pertencentes a _classe 2_ exclusivamente.
4. Em prolina todos os valores acima de 700 pertencem a _classe 1_

"""

sns.set()
for index,i in enumerate(grouped.columns,start=1):
    plt.figure(figsize=(6,4))
    sns.barplot(data=grouped,x=grouped.index,y=grouped[i])
    plt.show()

# transformador dtypes cor_intensidade em valores categoricos
df['Cor_intensidade'] = df['Cor_intensidade'].astype('category').cat.codes

#Gerando os histogramas
plt.figure(figsize= (25,15))
for i, column in enumerate(eda_data.columns):
  plt.subplot(4, 6, i +1)
  sns.histplot(data=eda_data[column])
  plt.title(column)
plt.tight_layout()
plt.show()

df.describe()

# Calcular a matriz de correla√ß√£o
df.corr()

corr = df.corr()
corr.style.background_gradient(cmap='RdBu', axis=None)

#criar um conjunto de gr√°ficos de dispers√£o para todas as combina√ß√µes de vari√°veis no DataFrame
sns.pairplot(df)

df.describe().T

group_soma = df.groupby('classe')
group_soma.sum()

"""# **3. Prepara√ß√£o dos Dados**

Durante a fase de prepara√ß√£o dos dados fez-se necess√°rio a convers√£o dos valores de *cor intensidade* para tipos num√©ricos que possam ser compreendidos e utilizados pelos algoritmos assim como no processo consist√™nte de an√°lise de dados.

Como investigado anteriormente, n√£o foram encontrados valores ausentes de qualquer tipo e ainda que existam distibui√ß√µes n√£o-gausseanas e enviesadas tampouco ocorreu a necessidade de normaliza√ß√£o.  

Quanto os valores fora de escopo, ou outliers, da forma que foram encontrados, foram considerados como ocorr√™ncias naturais e n√£o como erros. Devido a baixa ocorr√™ncia acreditamos que n√£o haver√£o impactos negativos significativos ao modelo.
"""

#visualiza√ß√£o r√°pida da presen√ßa de outliers
for column in df:
    plt.figure()
    df.boxplot([column])

"""# **4. Modelagem**

Dado que temos um problema de classifica√ß√£o, escolhemos as seguintes abordagens que atendem a este prop√≥sito:

##1. Random Forest

T√©cnica que costuma apresentar boa acur√°cia em problemas de classifica√ß√£o, permite avaliar o impacto das vari√°veis independentes, √© explic√°vel e de f√°cil compreens√£o. Por ser uma abordagem que funciona a partir da avalia√ß√£o e sele√ß√£o de v√°rios classificadores, tem um custo computacional maior que t√©cnicas mais simples, no entanto, justamente por se utilizar de v√°rias classifica√ß√µes costuma ser mais asssertiva.

Os dados foram divididos em conjuntos de treinamento(70%) e teste (30%).
### Treinando o modelo no algoritmo de RandomForest
"""



from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Inicializa√ß√£o do Modelo: RandomForestClassifier
modelo = RandomForestClassifier(random_state=2)

# Prepara√ß√£o dos Dados
# X cont√©m todas as caracter√≠sticas, excluindo a coluna 'classe'.
# y cont√©m apenas a coluna 'classe', que representa as classes a serem previstas.
X = df.drop(['classe'],axis=1)
y = df['classe']

# Divis√£o dos Dados em Conjuntos de Treinamento e Teste
# X_treino e y_treino s√£o os conjuntos de treinamento (70% dos dados).
# X_teste e y_teste s√£o os conjuntos de teste (30% dos dados).
# O uso de stratify=y garante que a distribui√ß√£o das classes seja mantida nos conjuntos de treinamento e teste.
X_treino,X_teste, y_treino, y_teste = train_test_split(X,y, test_size=0.3, random_state=42, stratify=y)

y_teste.shape

# Treinamento do Modelo
modelo.fit(X_treino,y_treino)

# Avalia√ß√£o do Modelo
acuracia = modelo.score(X_teste, y_teste)

# A acur√°cia √© uma m√©trica comum para avaliar o desempenho do modelo. Pode ser interpretada como a porcentagem de previs√µes corretas em rela√ß√£o ao total.
# Quanto mais pr√≥xima de 1.0, melhor √© o desempenho do modelo.
print(f'Acur√°cia do Modelo: {acuracia}')

sns.boxplot(X_treino, x=y_treino, y='Alcool')

"""Na rela√ß√£o de alcool e classes verificamos que os n√≠veis  mais altos de alcool est√£o presentes na _classe 1_ e os n√≠veis mais baixos na _classe 2_ onde tamb√©m observamos a ocorr√™ncia de dois poss√≠veis outliers acima de seu limite m√°ximo.  
 Na _classe 3_ se predominam os n√≠veis relativamente mais equilibrados de alcool. os dados contidos no intervalo intermodal parecem distintos quanto a seu n√≠vel de √°lcool.

Observando a distribui√ß√£o e a distin√ß√£o das classes quanto ao n√≠vel de alcool, podemos considerar os n√≠veis de alcool como um bom indicador para categorizar as classes.
"""

sns.violinplot(X_treino, x=y_treino, y='Alcool')

"""No gr√°fico violino em todas as classes temos uma distribui√ß√£o que podemos considerar unimodal. Observamos melhor onde se concentram a maior parte dos valores e adquirimos uma no√ß√£o melhor sobre a rela√ß√£o de n√≠veis de alcool e a categoriza√ß√£o por classe.   

Verificamos que, mesmo que a regi√£o do segundo quartil, que concentra a maior parte dos valores daquela classe, seja distinta entra as demais (quanto ao seu n√≠vel de √°lcool) temos uma presen√ßa significativa de valores entre duas ou mais classes apresentando os mesmos n√≠veis de alcool, sinificando que, embora seja um bom indicador, o n√≠vel de alcool seria capaz de determinar com boa acur√°cia a classe dos vinhos.
"""

sns.boxplot(X_treino, x=y_treino, y='Flavonoides')

"""Verificamos a distribui√ß√£o e rela√ß√£o da classe aos n√≠veis de Flavonoides no vinho, similar ao que fizemos com os n√≠veis de √°lcool.  

Tal como nos n√≠veis de √°lcool os limites intermodais tamb√©m mostram a presen√ßa de uma distin√ß√£o de classes para o n√≠vel de Flavonoides. Observando os limites superiores e inferiores observamos que os vinhos com maior valor de Flavonoides tendem a ser da _classe 1_ e os menores da _classe 2_
"""

correlacao = pd.concat([X_treino,y_treino],axis=1).corr()
correlacao.style.background_gradient(cmap='RdBu', axis=None)

modelo = RandomForestClassifier(random_state=2)
modelo.fit(X_treino,y_treino)
print(f'Score: {modelo.score(X_teste,y_teste)}')
importancia = pd.DataFrame({'colunas':X_treino.columns,'importancia':modelo.feature_importances_})

importancia_10 = importancia.sort_values(by="importancia", ascending=False).head(10)
plt.figure(figsize=(10,6))
ax = sns.barplot(x='colunas',y='importancia',data=importancia_10)
ax.set_xticklabels(ax.get_xticklabels(), rotation=75);

"""Por fim visualizamos o grau de import√¢ncia das vari√°veis para a classifica√ß√£o. Evidenciamos que Alcool e Flavonoides possuem alta relev√¢ncia para a determina√ß√£o das classes, algo que pode ser verificado anteriormente.  

Verificamos, por exemplo, que Total de Fenois possui uma import√¢ncia relativamente baixa para a classifica√ß√£o, mesmo que possua alto grau de correla√ß√£o com Flavonoides que tem alto grau de import√¢ncia e alto grau de correla√ß√£o negativa com classe, nosso Target.

Usando o grau de import√¢ncia podemos identificar quais vari√°veis s√£o realmente significativas para a classifica√ß√£o, podendo assim ter uma vis√£o mais compreensiva dos dados e se necess√°rio realizar sele√ß√£o de atributos.  
Por meio do que foi descrito e dos dados que conhecemos, conclu√≠mos que os n√≠veis de alcool, prolina, flavonoides e OD280/OD320 s√£o as principais vari√°veis necess√°rias para classificar vinhos entre as tr√™s classes de vinhos existentes.

### Usando o KFold

A valida√ß√£o do modelo de classifica√ß√£o a partir da separa√ß√£o dos dados em conjunto de treino e valida√ß√£o faz com que o resultado seja muito dependente dessa divis√£o dos dados e pode ser que, de forma aleat√≥ria, o padr√£o dos dados de valida√ß√£o sejam diferentes do padr√£o dos dados de treinamento, levando a sorte de ter um resultado muito melhor do que a realidade ou o azar de um resultado muito pior do que a realidade.

Levando isso em considera√ß√£o, √© poss√≠vel utilizar a valida√ß√£o cruzada, uma estrat√©gia mais consistente e bem mais utilizada nos projetos de machine learning.

Na valida√ß√£o cruzada, ao inv√©s de separarmos os dados em apenas treino e valida√ß√£o uma √∫nica vez, dividimos os dados em v√°rias partes de mesmo tamanho. Em cada uma dessas divis√µes, ser√° utilizada uma parte para valida√ß√£o e todas as outras para treinamento e o processo se repete at√© que todas as partes sejam utilizadas para valida√ß√£o e o restante para treinamento.

Ser√° gerado um modelo para cada uma dessas divis√µes e a avalia√ß√£o de desempenho ser√° feita tirando a m√©dia da m√©trica de cada modelo. Isso faz com que a depend√™ncia da separa√ß√£o dos dados seja eliminada, j√° que h√° uma varia√ß√£o maior da escolha dos dados e √© retirada uma m√©dia.

Geralmente s√£o utilizadas 5 ou 10 partes, mais do que isso n√£o √© t√£o necess√°rio porque necessita de um processamento maior e valores menores j√° mitiga o problema da escolha dos dados.
"""

# Valida√ß√£o Cruzada

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

previsores = df.iloc[:,0:13].values

previsores

previsores.shape

alvo = df.iloc[:,13].values

alvo.shape

## **An√°lise das escalas dos atributos (Escalonamento)**
df.describe()

# Utilizar√° a padroniza√ß√£o

from sklearn.preprocessing import StandardScaler

previsores_esc = StandardScaler().fit_transform(previsores)

previsoresdf = pd.DataFrame(previsores_esc)
previsoresdf

previsoresdf.describe()

# Criando o modelo
modelo_Random = RandomForestClassifier(criterion='entropy', random_state = 0, max_depth=3)
resultado_Random = cross_val_score(modelo_Random, previsores_esc, alvo, cv = kfold)

# Usamos a m√©dia e o desvio padr√£o
print("Acur√°cia M√©dia: %.2f%%" % (resultado_Random .mean() * 100.0))

"""## 2. √Årvore de decis√£o

Decidimos utilizar tamb√©m o algoritmo de √°rvore de decis√£o, que √© a base da t√©cnica anterior. Por ser um pouco mais simples, tem um custo computacional menor, o que justifica sua escolha caso os resultados obtidos sejam satisfat√≥rios.
O par√¢metro "criterion" foi definido como "entropy" na tentativa de aumentar o ganho de informa√ß√£o √† medida em que os n√≥s se aprofundam, reduzindo a aleatoriedade do n√≥ seguinte. Os conjuntos de treino e teste mantiveram a mesma propor√ß√£o, 70% e 30%, respectivamente.


## Treinando o modelo no algoritmo de √Årvore de Decis√£o
"""

# ARVORE DE DECIS√ÉO

from sklearn.tree import DecisionTreeClassifier

arvore = DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)
arvore.fit(X_treino, y_treino)

previsoes_arvore = arvore.predict(X_teste)
previsoes_arvore

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acur√°cia: %.2f%%" % (accuracy_score(y_teste, previsoes_arvore) * 100.0))

confusion_matrix(y_teste, previsoes_arvore)

print(classification_report(y_teste, previsoes_arvore))

#**An√°lise dados de treino**
previsoes_treino = arvore.predict(X_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# Valida√ß√£o Cruzada

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

previsores = df.iloc[:,0:13].values

previsores

previsores.shape

alvo = df.iloc[:,13].values

alvo

alvo.shape

## **An√°lise das escalas dos atributos (Escalonamento)**
df.describe()

# Utilizar√° a padroniza√ß√£o

from sklearn.preprocessing import StandardScaler

previsores_esc = StandardScaler().fit_transform(previsores)

previsoresdf = pd.DataFrame(previsores_esc)
previsoresdf

previsoresdf.describe()

# Criando o modelo
modelo = DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a m√©dia e o desvio padr√£o
print("Acur√°cia M√©dia: %.2f%%" % (resultado.mean() * 100.0))

"""## 3. KNN
O KNN √© um algoritmo simples que n√£o exige um treinamento expl√≠cito, sendo baseado no princ√≠pio da proximidade entre pontos de dados. Essa abordagem torna-o adapt√°vel a rela√ß√µes n√£o lineares nos dados, capturando padr√µes complexos de maneira eficaz. O KNN demonstra robustez em rela√ß√£o a outliers, (que, como visto anteriormente, foram mantidos) pois as previs√µes s√£o influenciadas por uma vizinhan√ßa local, minimizando o impacto de pontos isolados.  
 Sua facilidade de atualiza√ß√£o tamb√©m se destaca, permitindo a inclus√£o de novos dados sem a necessidade de re-treinamento completo, sendo portanto um bom modelo para eventualidades futuras, como adi√ß√£o de novos dados.
### Treinando o modelo no algoritmo de KNN
"""

# **APRENDIZAGEM BASEADA EM INST√ÇNCIAS (KNN)**

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=1)
knn.fit(X_treino, y_treino)

previsoes_knn = knn.predict(X_teste)
previsoes_knn

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acur√°cia: %.2f%%" % (accuracy_score(y_teste, previsoes_knn) * 100.0))

confusion_matrix(y_teste, previsoes_knn)

print(classification_report(y_teste, previsoes_knn))

previsoes_treino = knn.predict(X_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# VALIDA√á√ÉO CRUZADA

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 1)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a m√©dia e o desvio padr√£o
print("Acur√°cia M√©dia: %.2f%%" % (resultado.mean() * 100.0))

"""## 4. Regress√£o Log√≠stica
Escolhemos a regress√£o lo√≠stica por sua principal vantagem, a capacidade de modelar rela√ß√µes lineares entre os recursos considerando a probabilidade de pertencer a uma classe espec√≠fica. Isso facilita a interpreta√ß√£o dos coeficientes associados a cada vari√°vel, proporcionando insights sobre a contribui√ß√£o relativa de cada caracter√≠stica para a decis√£o de classifica√ß√£o.

Al√©m disso, a regress√£o log√≠stica lida bem com dados multiclasse.

### Treinando o modelo no algoritmo de Regress√£o Log√≠stica




"""

# **REGRESS√ÉO** LOG√çSTICA

from sklearn.linear_model import LogisticRegression

logistica = LogisticRegression(random_state=1, max_iter=600, penalty="l2",
                               tol=0.0001, C=1,solver="lbfgs")
logistica.fit(X_treino, y_treino)

logistica.intercept_

logistica.coef_

previsoes_logistica = logistica.predict(X_teste)
previsoes_logistica

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acur√°cia: %.2f%%" % (accuracy_score(y_teste, previsoes_logistica) * 100.0))

confusion_matrix(y_teste, previsoes_logistica)

print(classification_report(y_teste, previsoes_logistica))

# AN√ÅLISE DE DADOS DE TREINO
previsoes_treino = logistica.predict(X_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# VALIDA√á√ÉO CRUZADA
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = LogisticRegression(random_state=1, max_iter=600, penalty="l2",
                               tol=0.0001, C=1,solver="lbfgs")
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a m√©dia e o desvio padr√£o
print("Acur√°cia M√©dia: %.2f%%" % (resultado.mean() * 100.0))

"""## 5. SVM

Uma das principais vantagens das SVM √© sua efic√°cia em lidar com conjuntos de dados complexos. Ao buscar a melhor separa√ß√£o entre classes, as SVM buscam otimizar a margem entre os exemplos de treinamento, proporcionando uma generaliza√ß√£o robusta para novos dados.
### Treinando o modelo no algoritmo de SVM
"""

# SVM (Support Vector Machine)

from sklearn.svm import SVC

svm = SVC(kernel='rbf', random_state=1, C = 2)
svm.fit(X_treino, y_treino)

previsoes_svm = svm.predict(X_teste)
previsoes_svm

y_teste

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Acur√°cia: %.2f%%" % (accuracy_score(y_teste, previsoes_svm) * 100.0))

confusion_matrix(y_teste, previsoes_svm)

print(classification_report(y_teste, previsoes_svm))

# An√°lise dados de treino
previsoes_treino = svm.predict(X_treino)
previsoes_treino

accuracy_score(y_treino, previsoes_treino)

confusion_matrix(y_treino, previsoes_treino)

# VALIDA√á√ÉO CRUZADA

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# Separando os dados em folds
kfold = KFold(n_splits = 30, shuffle=True, random_state = 5)

# Criando o modelo
modelo = SVC(kernel='rbf', random_state=1, C = 2)
resultado = cross_val_score(modelo, previsores_esc, alvo, cv = kfold)

# Usamos a m√©dia e o desvio padr√£o
print("Acur√°cia M√©dia: %.2f%%" % (resultado.mean() * 100.0))

"""*Rodando* novamente o modelo com tamanho diferente"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

random_forest = RandomForestClassifier()
decision_tree = DecisionTreeClassifier()
knn = KNeighborsClassifier()
logistic_regression = LogisticRegression()
svm_model = SVC()


random_forest.fit(X_train, y_train)
decision_tree.fit(X_train, y_train)
knn.fit(X_train, y_train)
logistic_regression.fit(X_train, y_train)
svm_model.fit(X_train, y_train)

# Fa√ßa previs√µes nos dados de teste
rf_predictions = random_forest.predict(X_test)
dt_predictions = decision_tree.predict(X_test)
knn_predictions = knn.predict(X_test)
lr_predictions = logistic_regression.predict(X_test)
svm_predictions = svm_model.predict(X_test)

# Calcule as m√©tricas de avalia√ß√£o
rf_accuracy = accuracy_score(y_test, rf_predictions)
rf_f1 = f1_score(y_test, rf_predictions,pos_label='positive',average='micro')
rf_precision = precision_score(y_test, rf_predictions,pos_label='positive',average='micro')
rf_recall = recall_score(y_test, rf_predictions,pos_label='positive',average='micro')

dt_accuracy = accuracy_score(y_test, dt_predictions)
dt_f1 = f1_score(y_test, dt_predictions, pos_label='positive', average='micro')
dt_precision = precision_score(y_test, dt_predictions,pos_label='positive', average='micro')
dt_recall = recall_score(y_test, dt_predictions,pos_label='positive',average='micro')

knn_accuracy = accuracy_score(y_test, knn_predictions)
knn_f1 = f1_score(y_test, knn_predictions, pos_label='positive',average='micro')
knn_precision = precision_score(y_test, knn_predictions,pos_label='positive',average='micro')
knn_recall = recall_score(y_test, knn_predictions,pos_label='positive',average='micro')

lr_accuracy = accuracy_score(y_test, lr_predictions)
lr_f1 = f1_score(y_test, lr_predictions,pos_label='positive',average='micro')
lr_precision = precision_score(y_test, lr_predictions,pos_label='positive',average='micro')
lr_recall = recall_score(y_test, lr_predictions,pos_label='positive',average='micro')

svm_accuracy = accuracy_score(y_test, svm_predictions)
svm_f1 = f1_score(y_test, svm_predictions,pos_label='positive',average='micro')
svm_precision = precision_score(y_test, svm_predictions,pos_label='positive',average='micro')
svm_recall = recall_score(y_test, svm_predictions,pos_label='positive',average='micro')

# Crie a tabela com os resultados

data = {
    'Modelo': ['Random Forest', '√Årvore de Decis√£o', 'KNN', 'Regress√£o Log√≠stica', 'SVM'],
    'Acur√°cia': [rf_accuracy, dt_accuracy, knn_accuracy, lr_accuracy, svm_accuracy],
    'F1': [rf_f1, dt_f1, knn_f1, lr_f1, svm_f1],
    'Precis√£o': [rf_precision, dt_precision, knn_precision, lr_precision, svm_precision],
    'Recall': [rf_recall, dt_recall, knn_recall, lr_recall, svm_recall]
}

df = pd.DataFrame(data)
print(df)

from sklearn.model_selection import KFold, cross_val_score

# Defina o n√∫mero de folds
num_folds = 30  # Pode ajustar conforme necess√°rio

# Lista de modelos
models = [
    RandomForestClassifier(),
    DecisionTreeClassifier(),
    KNeighborsClassifier(),
    LogisticRegression(),
    SVC()
]

# Lista de nomes dos modelos
model_names = ['Random Forest', '√Årvore de Decis√£o', 'KNN', 'Regress√£o Log√≠stica', 'SVM']

# Lista para armazenar os resultados
results = {'Modelo': [], 'Acur√°cia': [], 'F1': [], 'Precis√£o': [], 'Recall': []}

# Loop atrav√©s dos modelos
for model, name in zip(models, model_names):
    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)

    # Realize a valida√ß√£o cruzada e obtenha as m√©tricas para cada fold
    accuracy = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy').mean()
    f1 = cross_val_score(model, X_train, y_train, cv=kfold, scoring='f1_micro').mean()
    precision = cross_val_score(model, X_train, y_train, cv=kfold, scoring='precision_micro').mean()
    recall = cross_val_score(model, X_train, y_train, cv=kfold, scoring='recall_micro').mean()

    # Armazene os resultados na lista
    results['Modelo'].append(name)
    results['Acur√°cia'].append(accuracy)
    results['F1'].append(f1)
    results['Precis√£o'].append(precision)
    results['Recall'].append(recall)

# Crie o DataFrame com os resultados
df_results = pd.DataFrame(results)
print('--------- VALIDA√á√ÉO CRUZADA --------------------')
print(df_results)

"""---
# Otimiza√ß√£o bayesiana para otimizar os hiperpar√¢metros.

---

A otimiza√ß√£o bayesiana √© um m√©todo para encontrar os melhores hiperpar√¢metros para um modelo de aprendizado de m√°quina. Ela se baseia em modelos probabil√≠sticos para modelar a fun√ß√£o objetivo (a m√©trica que voc√™ est√° tentando otimizar) e, com base nisso, escolhe as pr√≥ximas configura√ß√µes de hiperpar√¢metros a serem avaliadas.
"""

pip install scikit-optimize

from skopt import BayesSearchCV
from sklearn.model_selection import StratifiedKFold

# Defina os espa√ßos de busca para os hiperpar√¢metros de cada modelo
param_spaces = {
    'Random Forest': {
        'n_estimators': (10, 100),
        'max_depth': (1, 20),
        'min_samples_split': (2, 20),
        'min_samples_leaf': (1, 10)
    },
    '√Årvore de Decis√£o': {
        'max_depth': (1, 20),
        'min_samples_split': (2, 20),
        'min_samples_leaf': (1, 10)
    },
    'KNN': {
        'n_neighbors': (1, 20),
        'weights': ['uniform', 'distance']
    },
    'Regress√£o Log√≠stica': {
        'C': (1e-6, 1e+6),
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear']
    },
    'SVM': {
        'C': (1e-6, 1e+6),
        'kernel': ['linear', 'rbf', 'poly'],
        'degree': (1, 3),
    }
}

# Fun√ß√£o para otimiza√ß√£o bayesiana usando valida√ß√£o cruzada
def bayesian_optimization(model_name, model, param_space, X_train, y_train):
    opt = BayesSearchCV(model, param_space, n_iter=50, n_jobs=-1, cv=StratifiedKFold(n_splits=5), scoring='accuracy')
    opt.fit(X_train, y_train)

    print(f"Melhores hiperpar√¢metros para {model_name}: {opt.best_params_}")
    return opt.best_estimator_

# Dicion√°rio para armazenar os melhores modelos
best_models = {}

# Loop atrav√©s dos modelos
for model, name in zip(models, model_names):
    best_model = bayesian_optimization(name, model, param_spaces[name], X_train, y_train)
    best_models[name] = best_model

# Avalie os melhores modelos nos dados de teste
results = {'Modelo': [], 'Acur√°cia': [], 'F1': [], 'Precis√£o': [], 'Recall': []}

for name, model in best_models.items():
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    f1 = f1_score(y_test, predictions, pos_label='positive', average='micro')
    precision = precision_score(y_test, predictions, pos_label='positive', average='micro')
    recall = recall_score(y_test, predictions, pos_label='positive', average='micro')

    results['Modelo'].append(name)
    results['Acur√°cia'].append(accuracy)
    results['F1'].append(f1)
    results['Precis√£o'].append(precision)
    results['Recall'].append(recall)

# Crie o DataFrame com os resultados
df_results = pd.DataFrame(results)
print(df_results)

"""A otimiza√ß√£o bayesiana √© usada em conjunto com a valida√ß√£o cruzada para encontrar configura√ß√µes otimizadas que generalizam bem para diferentes conjuntos de dados.

# **5. Avalia√ß√£o**

Os algoritmos foram avaliados com base em suas acur√°cias, precis√£o, recall e F1-score, onde a Regress√£o Log√≠stica emerge como a melhor alternativa:

##Acur√°cia
A acur√°cia √© tida comumente como principal m√©trica de avalia√ß√£o e nos fornece a taxa de acertos do modelo, a seguir listamos as acu√°cias de cada modelo:

_Usando o Algoritmo de RandomForest obtivemos uma acur√°cia de 96% para a primeira itera√ß√£o_  
_Usando o Algoritmo de KNN obtivemos uma acur√°cia de 87% para a primeira itera√ß√£o_  
_Usando o Algoritimo √Årvore de decis√£o obtivemos uma acur√°cia de 93% para a primeira itera√ß√£o_  
_Usando o Algoritmo de Regress√£o Log√≠stica obtivemos uma acur√°cia de 98% para a primeira itera√ß√£o_  
_Usando o Algoritmo de SMV ovtivemos uma acur√°cia de 96% para a primeira itera√ß√£o_  

O algoritmo de Regress√£o Log√≠stica obteve a mais alta acur√°cia, atingindo **98%** na primeira itera√ß√£o, atingindo tamb√©m o maior grau de acur√°cia na segunda itera√ß√£o. A acur√°cia representa a propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de previs√µes. No entanto, a acur√°cia por si s√≥ pode ser enganadora, especialmente em conjuntos de dados desbalanceados.

##Precis√£o
A precis√£o √© a propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de predi√ß√µes positivas. A Regress√£o Log√≠stica apresentou a mais alta precis√£o em ambas as itera√ß√µes, indicando que, quando prev√™ uma classe positiva, √© mais prov√°vel que esteja correta. Isso √© crucial em situa√ß√µes em que falsos positivos s√£o indesejados.

##Recall
O recall representa a propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de inst√¢ncias positivas no conjunto de dados. Mais uma vez, a Regress√£o Log√≠stica obteve o melhor desempenho em recall em ambas as itera√ß√µes, indicando que consegue identificar uma alta propor√ß√£o de exemplos positivos.

##F1-Score
O F1-score √© a m√©dia harm√¥nica entre precis√£o e recall. Fornece uma medida balanceada entre essas duas m√©tricas. A Regress√£o Log√≠stica tamb√©m apresentou o maior F1-score em ambas as itera√ß√µes, o que refor√ßa sua capacidade de equilibrar precis√£o e recall de maneira eficaz.

##Finalmente...
Em Conclus√£o, Algoritmo de Regress√£o Log√≠stica obteve n√£o somente a maior acur√°cia como tamb√©m a mais alta precis√£o, _recall_ e _f1 score_, provando assim ser o melhor modelo para essa base de dados, dado o que quer√≠amos determinar.

-----

Em s√≠ntese, ao analisar m√©tricas como Acur√°cia, Precis√£o, Recall e F1-Score, destaca-se que a **Regress√£o Log√≠stica** emerge como a op√ß√£o mais apropriada para resolver este problema de classifica√ß√£o. Isso se deve ao seu not√°vel desempenho e maior habilidade em explicar varia√ß√µes nos dados. Contudo, √© crucial ponderar outros aspectos, como a complexidade do modelo, o tempo de treinamento e a interpretabilidade, no processo de escolha do modelo definitivo para uma dada problem√°tica.

## Agradecimento pelo aprendizado , Prof. Fl√°vio!!!! ‚úÖ::::: :
"""